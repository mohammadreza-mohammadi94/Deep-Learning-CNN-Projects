{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13836,
          "databundleVersionId": 1718836,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31193,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Cassava-Ensemble-ResNet-EffNet-MobileNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-CNN-Projects/blob/master/Ensemble-ResNet-EffNet-MobileNet-Cassava-Dataset/Cassava_Ensemble_ResNet_EffNet_MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "uw_Rg5Hx19UL"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "cassava_leaf_disease_classification_path = kagglehub.competition_download('cassava-leaf-disease-classification')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "M0XiFqpO19UN"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "jWed1JSY19UO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T13:11:45.34755Z",
          "iopub.execute_input": "2025-12-16T13:11:45.347721Z",
          "iopub.status.idle": "2025-12-16T13:12:01.837881Z",
          "shell.execute_reply.started": "2025-12-16T13:11:45.347705Z",
          "shell.execute_reply": "2025-12-16T13:12:01.837307Z"
        },
        "id": "cw_RWzTa19UP",
        "outputId": "10dca852-f474-4362-c297-e0627c241700"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "2025-12-16 13:11:48.160079: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765890708.331999      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765890708.379235      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
          ],
          "ename": "AttributeError",
          "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration & Setups"
      ],
      "metadata": {
        "id": "DtjSLZr_19UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset path\n",
        "BASE_DIR = \"/kaggle/input/cassava-leaf-disease-classification\"\n",
        "TRAIN_IMG_DIR = os.path.join(BASE_DIR, \"train_images\")\n",
        "TRAIN_CSV = os.path.join(BASE_DIR, \"train.csv\")\n",
        "\n",
        "# Hyperparameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "NUM_CLASSES = 5\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T13:12:01.839029Z",
          "iopub.execute_input": "2025-12-16T13:12:01.839458Z",
          "iopub.status.idle": "2025-12-16T13:12:01.843742Z",
          "shell.execute_reply.started": "2025-12-16T13:12:01.839439Z",
          "shell.execute_reply": "2025-12-16T13:12:01.842995Z"
        },
        "id": "8u6WGg_219UQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV\n",
        "df = pd.read_csv(TRAIN_CSV)\n",
        "df['image_path'] = df['image_id'].apply(lambda x: os.path.join(TRAIN_IMG_DIR, x))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T13:12:01.844637Z",
          "iopub.execute_input": "2025-12-16T13:12:01.845095Z",
          "iopub.status.idle": "2025-12-16T13:12:02.168794Z",
          "shell.execute_reply.started": "2025-12-16T13:12:01.845042Z",
          "shell.execute_reply": "2025-12-16T13:12:02.168023Z"
        },
        "id": "FJ47fVRL19UR"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified Split\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "print(f\"✅ Train samples: {len(train_df)}\")\n",
        "print(f\"✅ Val samples: {len(val_df)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T13:12:02.170504Z",
          "iopub.execute_input": "2025-12-16T13:12:02.170748Z",
          "iopub.status.idle": "2025-12-16T13:12:02.190691Z",
          "shell.execute_reply.started": "2025-12-16T13:12:02.170731Z",
          "shell.execute_reply": "2025-12-16T13:12:02.189886Z"
        },
        "id": "vmpt1YGh19UR",
        "outputId": "4e0e135b-a8af-4684-f08d-51a102e2df97"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "✅ Train samples: 17117\n✅ Val samples: 4280\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Pipeline `tf.data`"
      ],
      "metadata": {
        "id": "ZLpGtdoe19US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess(path, label):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, IMG_SIZE)\n",
        "    return img, label\n",
        "\n",
        "def augment(img, label):\n",
        "    img = tf.image.random_flip_left_right(img)\n",
        "    img = tf.image.random_flip_up_down(img)\n",
        "    img = tf.image.random_brightness(img, max_delta=0.2)\n",
        "    img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
        "    # Random rotation (90 deg) is safe for leaves\n",
        "    k = tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32)\n",
        "    img = tf.image.rot90(img, k)\n",
        "    return img, label\n",
        "\n",
        "def create_dataset(dataframe, is_train=False):\n",
        "    paths = dataframe['image_path'].values\n",
        "    labels = dataframe['label'].values\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    ds = ds.map(load_and_preprocess, num_parallel_calls=AUTOTUNE)\n",
        "    if is_train:\n",
        "        ds = ds.cache()\n",
        "        ds = ds.shuffle(1000)\n",
        "        ds = ds.map(augment, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "    ds = ds.batch(BATCH_SIZE)\n",
        "    ds = ds.prefetch(AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "# Build pipeline\n",
        "train_ds = create_dataset(train_df, is_train=True)\n",
        "val_ds = create_dataset(val_df, is_train=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T13:12:02.19169Z",
          "iopub.execute_input": "2025-12-16T13:12:02.192048Z",
          "iopub.status.idle": "2025-12-16T13:12:03.180611Z",
          "shell.execute_reply.started": "2025-12-16T13:12:02.192027Z",
          "shell.execute_reply": "2025-12-16T13:12:03.179722Z"
        },
        "id": "uuUmnwOX19US",
        "outputId": "8f9757e8-6110-48f1-b1e2-fd9cbc08e11e"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "I0000 00:00:1765890722.959272      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1765890722.959863      47 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Models"
      ],
      "metadata": {
        "id": "Op8ZhB7b19US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(model_name):\n",
        "    inputs = layers.Input(shape=(224, 224, 3))\n",
        "    if model_name == \"ResNet50\":\n",
        "        x = tf.keras.applications.resnet50.preprocess_input(inputs)\n",
        "        base_model = tf.keras.applications.ResNet50(\n",
        "            include_top=False,\n",
        "            weights='imagenet',\n",
        "            input_tensor=x\n",
        "        )\n",
        "    elif model_name == \"EfficientNetB0\":\n",
        "        # EfficientNet expects [0, 255] inputs (no manual scaling needed usually, but using keras util is safe)\n",
        "        # Note: EfficientNet usually has scaling built-in, so we pass raw inputs or standard scaling\n",
        "        x = inputs\n",
        "        base_model = tf.keras.applications.EfficientNetB0(\n",
        "            include_top=False,\n",
        "            weights=\"imagenet\",\n",
        "            input_tensor=x\n",
        "        )\n",
        "    elif model_name == \"MobileNetV2\":\n",
        "        x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
        "        base_model = tf.keras.applications.MobileNetV2(\n",
        "            include_top=False,\n",
        "            weights=\"imagenet\",\n",
        "            input_tensor=x\n",
        "        )\n",
        "\n",
        "    # Freeze the base model (Optional: Unfreeze for fine-tuning later)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Custom Head\n",
        "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name=model_name)\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T13:41:29.974815Z",
          "iopub.execute_input": "2025-12-16T13:41:29.975137Z",
          "iopub.status.idle": "2025-12-16T13:41:29.981875Z",
          "shell.execute_reply.started": "2025-12-16T13:41:29.975115Z",
          "shell.execute_reply": "2025-12-16T13:41:29.981056Z"
        },
        "id": "d_PexZQ419US"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "qW2fnxC819UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_stages(model_name, warmup_epochs=5, finetune_epochs=12):\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(f\"Processing Model: {model_name}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 1. Build Model\n",
        "    model = build_model(model_name)\n",
        "\n",
        "    # --- PHASE 1: Warm-up ---\n",
        "    # In build_model, we assumed base_model.trainable = False.\n",
        "    # So only the classification head is trainable now.\n",
        "\n",
        "    print(f\"\\nPhase 1: Warm-up (Head Only)\")\n",
        "    model.compile(optimizer=keras.optimizers.Adam(1e-3),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_ds, validation_data=val_ds, epochs=warmup_epochs, verbose=1)\n",
        "\n",
        "    # --- PHASE 2: Fine-Tuning (Smart Unfreezing) ---\n",
        "    print(f\"\\nPhase 2: Fine-Tuning (Last 50 Layers & BN Frozen)\")\n",
        "\n",
        "    # Unfreeze the whole model first\n",
        "    model.trainable = True\n",
        "\n",
        "    # Access the Base Model (Backbone)\n",
        "    # Usually it's the layer after Input and Preprocessing.\n",
        "    # We iterate to find the 'Functional' model inside.\n",
        "    base_model = None\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, keras.Model):\n",
        "            base_model = layer\n",
        "            break\n",
        "\n",
        "    if base_model:\n",
        "        # 1. Freeze all layers except the last 50\n",
        "        for layer in base_model.layers[:-50]:\n",
        "            layer.trainable = False\n",
        "\n",
        "        # 2. CRITICAL: Force BatchNormalization layers to stay frozen\n",
        "        # This prevents breaking the learned statistics from ImageNet\n",
        "        for layer in base_model.layers:\n",
        "            if isinstance(layer, layers.BatchNormalization):\n",
        "                layer.trainable = False\n",
        "\n",
        "        print(f\"   --> backbone configured: Top 50 layers unfrozen, BN layers frozen.\")\n",
        "\n",
        "    # Recompile with Low Learning Rate\n",
        "    model.compile(optimizer=keras.optimizers.Adam(1e-6), # 10x smaller LR\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Callbacks\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        f\"{model_name}_best.keras\", save_best_only=True, monitor='val_accuracy', mode='max', verbose=0\n",
        "    )\n",
        "    early_stop = keras.callbacks.EarlyStopping(\n",
        "        monitor='val_accuracy', patience=4, restore_best_weights=True, verbose=1\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    model.fit(train_ds, validation_data=val_ds, epochs=finetune_epochs,\n",
        "              callbacks=[checkpoint, early_stop], verbose=1)\n",
        "\n",
        "    print(f\"{model_name} Training Completed.\")\n",
        "    return"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T14:30:20.322021Z",
          "iopub.execute_input": "2025-12-16T14:30:20.322642Z",
          "iopub.status.idle": "2025-12-16T14:30:20.331781Z",
          "shell.execute_reply.started": "2025-12-16T14:30:20.32261Z",
          "shell.execute_reply": "2025-12-16T14:30:20.330869Z"
        },
        "id": "jknypZYy19UT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "models_list = ['ResNet50', 'EfficientNetB0', 'MobileNetV2']\n",
        "\n",
        "for m_name in models_list:\n",
        "    train_model_stages(m_name)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T14:30:20.699948Z",
          "iopub.execute_input": "2025-12-16T14:30:20.700205Z",
          "iopub.status.idle": "2025-12-16T14:58:38.347022Z",
          "shell.execute_reply.started": "2025-12-16T14:30:20.700186Z",
          "shell.execute_reply": "2025-12-16T14:58:38.346356Z"
        },
        "id": "lgCoQpNm19UT",
        "outputId": "5e15e18d-7460-4a26-9830-6d5df8bdbd1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n==================================================\nProcessing Model: ResNet50\n==================================================\n\nPhase 1: Warm-up (Head Only)\nEpoch 1/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 126ms/step - accuracy: 0.6348 - loss: 1.0660 - val_accuracy: 0.7189 - val_loss: 0.7699\nEpoch 2/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 111ms/step - accuracy: 0.7076 - loss: 0.8201 - val_accuracy: 0.7187 - val_loss: 0.7752\nEpoch 3/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 110ms/step - accuracy: 0.7179 - loss: 0.7836 - val_accuracy: 0.7180 - val_loss: 0.7881\nEpoch 4/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 110ms/step - accuracy: 0.7243 - loss: 0.7717 - val_accuracy: 0.7304 - val_loss: 0.7543\nEpoch 5/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 109ms/step - accuracy: 0.7217 - loss: 0.7775 - val_accuracy: 0.7348 - val_loss: 0.7501\n\nPhase 2: Fine-Tuning (Last 50 Layers & BN Frozen)\nEpoch 1/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 126ms/step - accuracy: 0.7334 - loss: 0.7562 - val_accuracy: 0.7383 - val_loss: 0.7347\nEpoch 2/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 112ms/step - accuracy: 0.7343 - loss: 0.7459 - val_accuracy: 0.7411 - val_loss: 0.7269\nEpoch 3/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 109ms/step - accuracy: 0.7339 - loss: 0.7428 - val_accuracy: 0.7411 - val_loss: 0.7226\nEpoch 4/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 112ms/step - accuracy: 0.7369 - loss: 0.7360 - val_accuracy: 0.7425 - val_loss: 0.7206\nEpoch 5/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 110ms/step - accuracy: 0.7405 - loss: 0.7345 - val_accuracy: 0.7416 - val_loss: 0.7194\nEpoch 6/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 110ms/step - accuracy: 0.7345 - loss: 0.7319 - val_accuracy: 0.7423 - val_loss: 0.7192\nEpoch 7/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 110ms/step - accuracy: 0.7326 - loss: 0.7396 - val_accuracy: 0.7425 - val_loss: 0.7186\nEpoch 8/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 110ms/step - accuracy: 0.7391 - loss: 0.7331 - val_accuracy: 0.7425 - val_loss: 0.7184\nEpoch 8: early stopping\nRestoring model weights from the end of the best epoch: 4.\nResNet50 Training Completed.\n\n==================================================\nProcessing Model: EfficientNetB0\n==================================================\n\nPhase 1: Warm-up (Head Only)\nEpoch 1/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 77ms/step - accuracy: 0.6548 - loss: 0.9616 - val_accuracy: 0.7210 - val_loss: 0.7514\nEpoch 2/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 47ms/step - accuracy: 0.7285 - loss: 0.7385 - val_accuracy: 0.7388 - val_loss: 0.7017\nEpoch 3/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 46ms/step - accuracy: 0.7437 - loss: 0.7114 - val_accuracy: 0.7484 - val_loss: 0.6866\nEpoch 4/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 47ms/step - accuracy: 0.7429 - loss: 0.7024 - val_accuracy: 0.7486 - val_loss: 0.6853\nEpoch 5/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 47ms/step - accuracy: 0.7503 - loss: 0.6898 - val_accuracy: 0.7467 - val_loss: 0.6870\n\nPhase 2: Fine-Tuning (Last 50 Layers & BN Frozen)\nEpoch 1/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 77ms/step - accuracy: 0.7524 - loss: 0.6845 - val_accuracy: 0.7474 - val_loss: 0.6845\nEpoch 2/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 49ms/step - accuracy: 0.7526 - loss: 0.6854 - val_accuracy: 0.7491 - val_loss: 0.6823\nEpoch 3/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7482 - loss: 0.6830 - val_accuracy: 0.7505 - val_loss: 0.6805\nEpoch 4/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7588 - loss: 0.6775 - val_accuracy: 0.7507 - val_loss: 0.6791\nEpoch 5/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7522 - loss: 0.6816 - val_accuracy: 0.7523 - val_loss: 0.6779\nEpoch 6/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7527 - loss: 0.6867 - val_accuracy: 0.7528 - val_loss: 0.6768\nEpoch 7/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7532 - loss: 0.6859 - val_accuracy: 0.7530 - val_loss: 0.6760\nEpoch 8/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7544 - loss: 0.6862 - val_accuracy: 0.7535 - val_loss: 0.6753\nEpoch 9/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7499 - loss: 0.6924 - val_accuracy: 0.7547 - val_loss: 0.6747\nEpoch 10/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 47ms/step - accuracy: 0.7470 - loss: 0.6905 - val_accuracy: 0.7547 - val_loss: 0.6742\nEpoch 11/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7535 - loss: 0.6726 - val_accuracy: 0.7551 - val_loss: 0.6736\nEpoch 12/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 48ms/step - accuracy: 0.7532 - loss: 0.6793 - val_accuracy: 0.7561 - val_loss: 0.6734\nRestoring model weights from the end of the best epoch: 12.\nEfficientNetB0 Training Completed.\n\n==================================================\nProcessing Model: MobileNetV2\n==================================================\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_47/4187861907.py:21: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base_model = tf.keras.applications.MobileNetV2(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\nPhase 1: Warm-up (Head Only)\nEpoch 1/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.6250 - loss: 1.0874 - val_accuracy: 0.7119 - val_loss: 0.7674\nEpoch 2/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - accuracy: 0.6986 - loss: 0.8235 - val_accuracy: 0.7248 - val_loss: 0.7398\nEpoch 3/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.7064 - loss: 0.7918 - val_accuracy: 0.7320 - val_loss: 0.7356\nEpoch 4/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.7103 - loss: 0.7930 - val_accuracy: 0.7273 - val_loss: 0.7409\nEpoch 5/5\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.7177 - loss: 0.7846 - val_accuracy: 0.7357 - val_loss: 0.7327\n\nPhase 2: Fine-Tuning (Last 50 Layers & BN Frozen)\nEpoch 1/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 53ms/step - accuracy: 0.7239 - loss: 0.7635 - val_accuracy: 0.7383 - val_loss: 0.7259\nEpoch 2/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - accuracy: 0.7199 - loss: 0.7661 - val_accuracy: 0.7381 - val_loss: 0.7215\nEpoch 3/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - accuracy: 0.7289 - loss: 0.7520 - val_accuracy: 0.7418 - val_loss: 0.7186\nEpoch 4/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - accuracy: 0.7289 - loss: 0.7491 - val_accuracy: 0.7425 - val_loss: 0.7168\nEpoch 5/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - accuracy: 0.7293 - loss: 0.7494 - val_accuracy: 0.7425 - val_loss: 0.7157\nEpoch 6/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - accuracy: 0.7268 - loss: 0.7519 - val_accuracy: 0.7432 - val_loss: 0.7150\nEpoch 7/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - accuracy: 0.7264 - loss: 0.7539 - val_accuracy: 0.7421 - val_loss: 0.7144\nEpoch 8/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - accuracy: 0.7256 - loss: 0.7531 - val_accuracy: 0.7430 - val_loss: 0.7140\nEpoch 9/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - accuracy: 0.7271 - loss: 0.7481 - val_accuracy: 0.7435 - val_loss: 0.7137\nEpoch 10/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - accuracy: 0.7315 - loss: 0.7455 - val_accuracy: 0.7435 - val_loss: 0.7136\nEpoch 11/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - accuracy: 0.7265 - loss: 0.7507 - val_accuracy: 0.7446 - val_loss: 0.7133\nEpoch 12/12\n\u001b[1m535/535\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 40ms/step - accuracy: 0.7303 - loss: 0.7527 - val_accuracy: 0.7449 - val_loss: 0.7132\nRestoring model weights from the end of the best epoch: 12.\nMobileNetV2 Training Completed.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Soft Voting"
      ],
      "metadata": {
        "id": "Htjut6Td19UT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Calculating Ensemble Results\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Load best saved models\n",
        "m_resnet = keras.models.load_model('ResNet50_best.keras')\n",
        "m_effnet = keras.models.load_model('EfficientNetB0_best.keras')\n",
        "m_mobile = keras.models.load_model('MobileNetV2_best.keras')\n",
        "\n",
        "# Get ground truth (Concatenate all batches from val_ds)\n",
        "y_true = np.concatenate([y for x, y in val_ds], axis=0)\n",
        "\n",
        "# Make Predictions\n",
        "print(\">> Predicting ResNet50...\")\n",
        "p_resnet = m_resnet.predict(val_ds, verbose=1)\n",
        "\n",
        "print(\">> Predicting EfficientNetB0...\")\n",
        "p_effnet = m_effnet.predict(val_ds, verbose=1)\n",
        "\n",
        "print(\">> Predicting MobileNetV2...\")\n",
        "p_mobile = m_mobile.predict(val_ds, verbose=1)\n",
        "\n",
        "# Individual Accuracy\n",
        "acc_r = accuracy_score(y_true, np.argmax(p_resnet, axis=1))\n",
        "acc_e = accuracy_score(y_true, np.argmax(p_effnet, axis=1))\n",
        "acc_m = accuracy_score(y_true, np.argmax(p_mobile, axis=1))\n",
        "\n",
        "print(f\"\\nIndividual Accuracies:\")\n",
        "print(f\"   ResNet50:       {acc_r:.2%}\")\n",
        "print(f\"   EfficientNetB0: {acc_e:.2%}\")\n",
        "print(f\"   MobileNetV2:    {acc_m:.2%}\")\n",
        "\n",
        "# Ensemble (Average Probability)\n",
        "ensemble_preds = (p_resnet + p_effnet + p_mobile) / 3.0\n",
        "ensemble_labels = np.argmax(ensemble_preds, axis=1)\n",
        "acc_ensemble = accuracy_score(y_true, ensemble_labels)\n",
        "\n",
        "print(f\"\\nEnsemble Accuracy: {acc_ensemble:.2%}\")\n",
        "\n",
        "# Check improvement\n",
        "best_single = max(acc_r, acc_e, acc_m)\n",
        "print(f\"Boost over best single model: +{acc_ensemble - best_single:.2%}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-12-16T14:58:38.348688Z",
          "iopub.execute_input": "2025-12-16T14:58:38.348897Z",
          "iopub.status.idle": "2025-12-16T14:59:37.621741Z",
          "shell.execute_reply.started": "2025-12-16T14:58:38.34888Z",
          "shell.execute_reply": "2025-12-16T14:59:37.620985Z"
        },
        "id": "rO63ldHT19UT",
        "outputId": "3b0f4e7c-4606-45d8-f8cd-06e16bdb2207"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n==================================================\nCalculating Ensemble Results\n==================================================\n>> Predicting ResNet50...\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 108ms/step\n>> Predicting EfficientNetB0...\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 88ms/step\n>> Predicting MobileNetV2...\n\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 65ms/step\n\nIndividual Accuracies:\n   ResNet50:       74.25%\n   EfficientNetB0: 75.61%\n   MobileNetV2:    74.49%\n\nEnsemble Accuracy: 76.45%\nBoost over best single model: +0.84%\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "UOsd6xXR19UU"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}